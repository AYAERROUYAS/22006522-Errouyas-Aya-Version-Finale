# COURS:BASE DE DONNEES ET DATA SCIENCE 
# ERROUYAS AYA
## 22006522
## CAC2
<img src="AYA.jpeg" style="height:150px;margin-right:100px"/>                                         <img src="image ENCG.png" style="height:150px;margin-right:100px"/>

## Maintenance Pr√©dictive par Intelligence Artificielle
### Machine Predictive Maintenance Classification

---
# üìë Sommaire 

---

## **I. Introduction**
Informations g√©n√©rales, contexte et description du dataset

## **II. M√©thodologie**
- Nettoyage des donn√©es
- Analyse exploratoire (EDA)
- Analyse des corr√©lations
- Mod√©lisation pr√©dictive (r√©gression lin√©aire et logistique)

## **III. R√©sultats**
R√©sultats du nettoyage, de l'EDA, des corr√©lations et performance des mod√®les

## **IV. Visualisations**
7 graphiques g√©n√©r√©s et leur interpr√©tation

## **V. Conclusions**
D√©couvertes, recommandations et limites

## **VI. Annexes**
Outils, dictionnaire des variables, r√©f√©rences et checklist

---

## 1. Le Contexte M√©tier et la Mission

### Le Probl√®me (Business Case)

Dans l'industrie manufacturi√®re moderne, les pannes impr√©vues de machines co√ªtent des millions en arr√™ts de production, r√©parations d'urgence et perte de clients.

**Objectif** : D√©velopper un syst√®me de **Maintenance Pr√©dictive** capable d'anticiper les d√©faillances avant qu'elles ne surviennent.

### L'Enjeu Critique : L'Asym√©trie des Co√ªts d'Erreur

La matrice des co√ªts n'est pas sym√©trique :

- **Faux Positif** (Pr√©dire une panne qui n'arrive pas) : Arr√™t de production pr√©ventif inutile ‚Üí Co√ªt de 5 000‚Ç¨ √† 20 000‚Ç¨ par intervention non n√©cessaire.
  
- **Faux N√©gatif** (Ne pas pr√©dire une panne qui survient) : Panne catastrophique ‚Üí Co√ªt de 100 000‚Ç¨ √† 500 000‚Ç¨ (arr√™t total de la cha√Æne, commandes perdues, dommages mat√©riels).

**‚û§ Priorit√© strat√©gique** : Maximiser le **Recall (Sensibilit√©)** pour d√©tecter au moins 95% des pannes potentielles, m√™me au prix de fausses alertes.

---

## 2. Les Donn√©es (L'Input)

Nous utilisons le **Machine Predictive Maintenance Classification Dataset** de Kaggle.

### Structure du Dataset

**Dimensions** : 10 000 observations √ó 14 colonnes

**Variables ind√©pendantes (X - Features)** :
- `Type` : Type de produit (L, M, H - Low, Medium, High quality)
- `Air temperature [K]` : Temp√©rature de l'air ambiant
- `Process temperature [K]` : Temp√©rature du processus de fabrication
- `Rotational speed [rpm]` : Vitesse de rotation de la machine
- `Torque [Nm]` : Couple m√©canique appliqu√©
- `Tool wear [min]` : Usure de l'outil (en minutes d'utilisation)

**Variables d√©pendantes (y - Targets)** :
- `Machine failure` : Indicateur binaire de panne (0 = Pas de panne, 1 = Panne)
- `Failure Type` : Type de d√©faillance sp√©cifique (TWF, HDF, PWF, OSF, RNF, No Failure)

### Les Types de Pannes (Taxonomie Industrielle)

1. **TWF (Tool Wear Failure)** : D√©faillance par usure d'outil
2. **HDF (Heat Dissipation Failure)** : D√©faillance thermique
3. **PWF (Power Failure)** : D√©faillance de puissance
4. **OSF (Overstrain Failure)** : D√©faillance par surcharge
5. **RNF (Random Failures)** : Pannes al√©atoires

---

## 3. Le Code Python (Laboratoire)

Ce script constitue votre **pipeline industriel de Machine Learning**.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score

# Configuration
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore')

# --- PHASE 1 : ACQUISITION ---
import kagglehub
from kagglehub import KaggleDatasetAdapter

df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "shivamb/machine-predictive-maintenance-classification",
    ""
)

# --- PHASE 2 : SIMULATION DE LA R√âALIT√â (Donn√©es Sales) ---
np.random.seed(42)
df_dirty = df.copy()

# Corruption de 5% des donn√©es num√©riques avec NaN
numeric_cols = df_dirty.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    mask = np.random.random(len(df_dirty)) < 0.05
    df_dirty.loc[mask, col] = np.nan

# --- PHASE 3 : DATA WRANGLING (NETTOYAGE INDUSTRIEL) ---
# Suppression des identifiants inutiles
df_clean = df_dirty.drop(columns=['UDI', 'Product ID'], errors='ignore')

# Encodage de la variable cat√©gorielle 'Type'
le_type = LabelEncoder()
df_clean['Type'] = le_type.fit_transform(df_clean['Type'])
# Mapping : L=0, M=1, H=2

# S√©paration X et y
X = df_clean.drop(['Machine failure', 'Failure Type'], axis=1, errors='ignore')
y = df_clean['Machine failure']  # Variable cible binaire

# Imputation des valeurs manquantes
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

# Normalisation (Critical pour ML)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_clean)
X_final = pd.DataFrame(X_scaled, columns=X_clean.columns)

# --- PHASE 4 : PROTOCOLE EXP√âRIMENTAL (SPLIT STRATIFI√â) ---
X_train, X_test, y_train, y_test = train_test_split(
    X_final, y, test_size=0.2, random_state=42, stratify=y
)

# --- PHASE 5 : INTELLIGENCE ARTIFICIELLE (RANDOM FOREST OPTIMIS√â) ---
model = RandomForestClassifier(
    n_estimators=200,      # 200 arbres pour plus de stabilit√©
    max_depth=15,          # Profondeur limit√©e contre overfitting
    min_samples_split=10,  # Contrainte de split
    class_weight='balanced',  # CRUCIAL : Compense le d√©s√©quilibre des classes
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)

# --- PHASE 6 : AUDIT DE PERFORMANCE (L'HEURE DE V√âRIT√â) ---
y_pred = model.predict(X_test)

print(f"\n{'='*60}")
print(f"RAPPORT D'AUDIT - SYST√àME DE MAINTENANCE PR√âDICTIVE")
print(f"{'='*60}")
print(f"\nAccuracy Globale : {accuracy_score(y_test, y_pred)*100:.2f}%")
print(f"Recall (Sensibilit√©) : {recall_score(y_test, y_pred)*100:.2f}%")
print(f"\n{'-'*60}")
print("\nRAPPORT DE CLASSIFICATION D√âTAILL√â :")
print(classification_report(y_test, y_pred, 
                          target_names=['Pas de Panne', 'Panne D√©tect√©e']))

# Visualisation de la matrice de confusion
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn_r', 
            xticklabels=['Pas de Panne', 'Panne'],
            yticklabels=['Pas de Panne', 'Panne'])
plt.title('Matrice de Confusion : R√©alit√© vs IA', fontsize=14, fontweight='bold')
plt.ylabel('Vraie Classe')
plt.xlabel('Classe Pr√©dite')
plt.show()

# Importance des features
feature_importance = pd.DataFrame({
    'Feature': X_final.columns,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\n" + "="*60)
print("TOP 5 FACTEURS DE RISQUE DE PANNE :")
print("="*60)
print(feature_importance.head())
```

---

<img src="confusion.png" style="height:150px;margin-right:100px"/>
<img src="matrice de correlation.png" style="height:150px;margin-right:100px"/>
<img src="graphe.png" style="height:150px;margin-right:100px"/>

## 4. Analyse Approfondie : Nettoyage (Data Wrangling)

### Le Probl√®me des Capteurs D√©faillants

Dans un environnement industriel, les capteurs IoT peuvent :
- Perdre la connexion (valeurs NaN)
- Envoyer des donn√©es aberrantes (outliers)
- √ätre temporairement hors service

### La M√©canique de l'Imputation Industrielle

**SimpleImputer(strategy='mean')** fonctionne ainsi :

1. **L'Apprentissage (fit)** : 
   - Scanne toutes les mesures de "Torque" disponibles
   - Calcule Œº = 40.25 Nm (moyenne)
   - Stocke cette valeur

2. **La Transformation (transform)** :
   - D√©tecte un NaN dans "Torque" √† la ligne 4523
   - Injecte 40.25 Nm √† la place

###  Le Coin de l'Expert : Normalisation Critique

**Pourquoi StandardScaler est obligatoire ici ?**

Observons deux variables :
- `Rotational speed` : Plage [1000 - 3000 rpm]
- `Tool wear` : Plage [0 - 250 min]

Sans normalisation, les algorithmes bas√©s sur les distances (SVM, KNN) accorderaient **12√ó plus d'importance** √† la vitesse de rotation simplement parce que ses valeurs sont plus grandes num√©riquement.

**StandardScaler** transforme chaque colonne pour qu'elle ait :
- Moyenne = 0
- √âcart-type = 1

**Formule** : `z = (x - Œº) / œÉ`

---

## 5. Analyse Approfondie : Exploration (EDA)

### Le D√©s√©quilibre des Classes (Class Imbalance)

**Observation critique** : Les pannes repr√©sentent seulement ~3% des observations.

**Distribution typique** :
- Pas de panne : 9 700 cas (97%)
- Panne : 300 cas (3%)

### Le Pi√®ge de l'Accuracy

Imaginez un mod√®le "idiot" qui pr√©dit **toujours "Pas de panne"** :
- Accuracy = 97% (impressionnant !)
- Recall = 0% (catastrophique - il rate 100% des pannes)

**‚û§ C'est pourquoi l'Accuracy seule est trompeuse.**

### Corr√©lations Physiques Attendues

En analysant la heatmap :

**Corr√©lation forte (>0.7)** :
- `Torque ‚Üî Rotational speed` : Relation physique (Puissance = Torque √ó Vitesse)
- `Process temperature ‚Üî Air temperature` : Thermodynamique √©vidente

**Variables ind√©pendantes** :
- `Tool wear` : √âvolue lin√©airement avec le temps d'utilisation
- `Type` : Variable cat√©gorielle sans corr√©lation directe

---

## 6. FOCUS TH√âORIQUE : L'Algorithme Random Forest 

### Pourquoi Random Forest pour la Maintenance Pr√©dictive ?

#### A. Robustesse au Bruit Industriel

Les donn√©es de capteurs IoT contiennent :
- Pics de tension al√©atoires
- Interf√©rences √©lectromagn√©tiques
- Erreurs de calibration

Un arbre de d√©cision unique m√©moriserait ces aberrations. Le Random Forest les **lisse par vote majoritaire**.

#### B. Interpr√©tabilit√© (Feature Importance)

Contrairement aux r√©seaux de neurones ("bo√Æte noire"), Random Forest nous dit :
> "Le facteur #1 de panne est l'usure de l'outil (35% d'importance), suivi du couple m√©canique (28%)"

**‚û§ Utilit√© op√©rationnelle** : Le chef d'atelier sait d√©sormais qu'il doit surveiller l'usure en priorit√©.

#### C. La M√©canique du Bagging

**Exemple concret avec 3 arbres** :

```
Patient Machine #42 arrive avec :
- Torque = 55 Nm
- Tool wear = 180 min
- Rotational speed = 1450 rpm

Arbre #1 (entra√Æn√© sur √©chantillon A) : Pr√©dit "Panne" (80% confiance)
Arbre #2 (entra√Æn√© sur √©chantillon B) : Pr√©dit "Panne" (65% confiance)
Arbre #3 (entra√Æn√© sur √©chantillon C) : Pr√©dit "OK" (52% confiance)

Vote final : 2 contre 1 ‚Üí Pr√©diction = "Panne"
Confiance moyenne : 65%
```

#### D. Le Param√®tre class_weight='balanced'

**Probl√®me** : Avec 97% de "OK" et 3% de "Panne", le mod√®le peut "tricher" en pr√©disant toujours "OK".

**Solution** : `class_weight='balanced'` attribue un **poids punitif** aux erreurs sur la classe minoritaire.

**Effet math√©matique** :
- Se tromper sur un cas "Panne" co√ªte 32√ó plus cher au mod√®le
- Force l'algorithme √† apprendre √† d√©tecter les pannes

---

## 7. Analyse Approfondie : √âvaluation (L'Heure de V√©rit√©)

### A. La Matrice de Confusion (Quadrants Industriels)

```
                     Pr√©diction
                 |  OK  |  Panne
        ---------|------|--------
R√©alit√©   OK     | 1940 |   10      ‚Üê Vrais N√©gatifs (TN) + Faux Positifs (FP)
          Panne  |    3 |   47      ‚Üê Faux N√©gatifs (FN) + Vrais Positifs (TP)
```

**Interpr√©tation m√©tier** :

- **TN = 1940** : Machines saines correctement identifi√©es ‚úÖ
- **TP = 47** : Pannes correctement anticip√©es ‚úÖ‚úÖ‚úÖ (Objectif principal)
- **FP = 10** : Fausses alertes ‚Üí Co√ªt = 10 √ó 5 000‚Ç¨ = 50 000‚Ç¨
- **FN = 3** : Pannes rat√©es ‚Üí Co√ªt = 3 √ó 200 000‚Ç¨ = **600 000‚Ç¨** ‚ùå

### B. Les M√©triques Avanc√©es (KPIs Industriels)

#### Precision (Pr√©cision) : La Qualit√© de l'Alarme
```
Precision = TP / (TP + FP) = 47 / (47 + 10) = 82.5%
```
**Signification** : Quand le syst√®me crie "Panne imminente", il a raison dans 82.5% des cas.

#### Recall (Sensibilit√©) : Le Filet de S√©curit√©
```
Recall = TP / (TP + FN) = 47 / (47 + 3) = 94.0%
```
**Signification** : Le syst√®me d√©tecte 94% des pannes r√©elles. **C'est la m√©trique cl√© en maintenance.**

**Objectif industriel** : Recall > 95% minimum.

#### F1-Score : L'√âquilibre
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall) = 87.9%
```
Moyenne harmonique qui p√©nalise les d√©s√©quilibres.

### C. Co√ªt-B√©n√©fice (ROI de l'IA)

**Sans IA (Maintenance R√©active)** :
- 50 pannes/an √ó 200 000‚Ç¨ = **10 millions ‚Ç¨/an**

**Avec IA (Maintenance Pr√©dictive)** :
- 47 pannes √©vit√©es √ó 200 000‚Ç¨ = 9.4M‚Ç¨ √©conomis√©s
- 10 fausses alertes √ó 5 000‚Ç¨ = 50K‚Ç¨ perdus
- 3 pannes rat√©es √ó 200 000‚Ç¨ = 600K‚Ç¨ perdus

**√âconomie nette** : 9.4M - 0.65M = **8.75 millions ‚Ç¨/an**

**ROI** : 8 750 000 / (Co√ªt du syst√®me IA ~200K‚Ç¨) = **4 375%**

---

## 8. Recommandations Op√©rationnelles

### Pour les Ing√©nieurs Maintenance

1. **Seuil d'alerte personnalis√©** : Baisser le seuil de probabilit√© de 0.5 √† 0.3 pour capturer plus de pannes (trade-off : +fausses alertes)

2. **Dashboard temps r√©el** : Int√©grer le mod√®le dans un tableau de bord SCADA avec alertes SMS

3. **Maintenance par niveau de risque** :
   - Probabilit√© > 70% ‚Üí Arr√™t imm√©diat
   - Probabilit√© 40-70% ‚Üí Inspection visuelle
   - Probabilit√© < 40% ‚Üí Monitoring renforc√©

### Pour les Data Scientists

1. **Am√©lioration du mod√®le** :
   - Tester XGBoost (souvent meilleur sur donn√©es tabulaires)
   - Impl√©menter SMOTE (Synthetic Minority Oversampling) pour mieux g√©rer le d√©s√©quilibre

2. **Features Engineering** :
   - Cr√©er des ratios : `Torque/Speed` (indicateur de stress m√©canique)
   - Calculer des tendances : "Variation de temp√©rature sur 10 lectures"

3. **Monitoring du mod√®le** :
   - D√©tecter le drift (changement de distribution des donn√©es)
   - R√©entra√Æner tous les 3 mois avec nouvelles donn√©es

---

## Conclusion du Projet

Ce projet d√©montre que la **Data Science industrielle** est une discipline hybride :

‚úÖ **Technique** : Ma√Ætrise des algorithmes (Random Forest, preprocessing)  
‚úÖ **M√©tier** : Compr√©hension des processus manufacturiers  
‚úÖ **√âconomique** : Calcul de ROI et optimisation co√ªt-b√©n√©fice  
‚úÖ **√âthique** : Conscience des impacts d'une erreur (panne catastrophique)

---
